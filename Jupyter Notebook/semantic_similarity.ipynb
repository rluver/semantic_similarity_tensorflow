{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertConfig, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizer(label):\n",
    "    \n",
    "    if label == 'entailment':\n",
    "        return 2\n",
    "    elif label == 'neutral':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def get_similarity(sentence1, sentence2):\n",
    "    \n",
    "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
    "    test_data = BertSemanticDataGenerator(\n",
    "        sentence_pairs, \n",
    "        labels = None, \n",
    "        batch_size = 1, \n",
    "        shuffle = False, \n",
    "        include_targets = False\n",
    "    )\n",
    "\n",
    "    proba = model.predict(test_data)[0]\n",
    "    idx = np.argmax(proba)\n",
    "    proba = f\"{proba[idx] * 100: .2f}%\"\n",
    "    pred = labels[idx]\n",
    "    \n",
    "    return pred, proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(max_length, gpus = False):\n",
    "    \n",
    "    if gpus >= 2:\n",
    "        \n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        with strategy.scope():\n",
    "\n",
    "            input_ids = Input(\n",
    "                shape = (max_length, ), dtype = tf.int32, name = 'input_ids'\n",
    "            )\n",
    "            attention_masks = tf.keras.layers.Input(\n",
    "                shape = (max_length, ), dtype = tf.int32, name = 'attention_masks'\n",
    "            )\n",
    "            token_type_ids = tf.keras.layers.Input(\n",
    "                shape = (max_length, ), dtype = tf.int32, name = 'segment_ids'\n",
    "            )\n",
    "\n",
    "            # model load\n",
    "            config = BertConfig.from_pretrained(r'model', output_hidden_states = True)\n",
    "            bert_model = bert_model = TFBertModel.from_pretrained(r'model', from_pt = True, config = config)\n",
    "            # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
    "            bert_model.trainable = False\n",
    "\n",
    "            outputs = bert_model([input_ids, token_type_ids, attention_masks])\n",
    "            sequence_output, _ = outputs.last_hidden_state, outputs.pooler_output\n",
    "            # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
    "            bi_lstm = Bidirectional(\n",
    "                LSTM(units = 64, return_sequences = True)\n",
    "            )(sequence_output)\n",
    "            # Applying hybrid pooling approach to bi_lstm sequence output.\n",
    "            avg_pool = GlobalAveragePooling1D()(bi_lstm)\n",
    "            max_pool = GlobalMaxPooling1D()(bi_lstm)\n",
    "            concat = concatenate([avg_pool, max_pool])\n",
    "            dropout = Dropout(rate = 0.3)(concat)\n",
    "            output = Dense(units = 3, activation = 'softmax')(dropout)\n",
    "            model = Model(\n",
    "                inputs = [input_ids, token_type_ids, attention_masks], \n",
    "                outputs = output\n",
    "            )\n",
    "\n",
    "            model.compile(\n",
    "                optimizer = Adam(),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'],\n",
    "            )\n",
    "\n",
    "            model.summary()\n",
    "\n",
    "            return model\n",
    "        \n",
    "    else:\n",
    "        input_ids = Input(\n",
    "                shape = (max_length, ), dtype = tf.int32, name = 'input_ids'\n",
    "            )\n",
    "        attention_masks = tf.keras.layers.Input(\n",
    "            shape = (max_length, ), dtype = tf.int32, name = 'attention_masks'\n",
    "        )\n",
    "        token_type_ids = tf.keras.layers.Input(\n",
    "            shape = (max_length, ), dtype = tf.int32, name = 'segment_ids'\n",
    "        )\n",
    "\n",
    "        # model load\n",
    "        config = BertConfig.from_pretrained(r'model', output_hidden_states = True)\n",
    "        bert_model = bert_model = TFBertModel.from_pretrained(r'model', from_pt = True, config = config)\n",
    "        # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
    "        bert_model.trainable = False\n",
    "\n",
    "        outputs = bert_model([input_ids, token_type_ids, attention_masks])\n",
    "        sequence_output, _ = outputs.last_hidden_state, outputs.pooler_output\n",
    "        # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
    "        bi_lstm = Bidirectional(\n",
    "            LSTM(units = 64, return_sequences = True)\n",
    "        )(sequence_output)\n",
    "        # Applying hybrid pooling approach to bi_lstm sequence output.\n",
    "        avg_pool = GlobalAveragePooling1D()(bi_lstm)\n",
    "        max_pool = GlobalMaxPooling1D()(bi_lstm)\n",
    "        concat = concatenate([avg_pool, max_pool])\n",
    "        dropout = Dropout(rate = 0.3)(concat)\n",
    "        output = Dense(units = 3, activation = 'softmax')(dropout)\n",
    "        model = Model(\n",
    "            inputs = [input_ids, token_type_ids, attention_masks], \n",
    "            outputs = output\n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer = Adam(),\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics = ['accuracy'],\n",
    "        )\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(Sequence):\n",
    "    \"\"\"Generates batches of data.\n",
    "    Args:\n",
    "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
    "        labels: Array of labels.\n",
    "        batch_size: Integer batch size.\n",
    "        shuffle: boolean, whether to shuffle the data.\n",
    "        include_targets: boolean, whether to incude the labels.\n",
    "    Returns:\n",
    "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
    "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
    "         if `include_targets=False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size,\n",
    "        shuffle = True,\n",
    "        include_targets = True,\n",
    "        max_len = 128\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets        \n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = FullTokenizer('vocab.korean.rawtext.list')\n",
    "        self.max_len = max_len\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "    \n",
    "    \n",
    "\n",
    "    def get_batch_bert_input_data(self, sentence_pairs):\n",
    "        \n",
    "    \n",
    "        sentence_pairs = list(map(lambda x: ' '.join(['[CLS]', x[0], '[SEP]', x[1], '[SEP]']), sentence_pairs))\n",
    "    \n",
    "        input_ids = map(lambda x: self.tokenizer.wordpiece_tokenizer.tokenize(x), sentence_pairs)\n",
    "        input_ids = list(map(lambda x: self.tokenizer.convert_tokens_to_ids(x), input_ids))\n",
    "                \n",
    "        mask_array = list(map(lambda x: [1] * len(x), input_ids))\n",
    "        input_mask_array = pad_sequences(mask_array, maxlen = self.max_len, padding = 'post')\n",
    "        \n",
    "        segment_index_lists = list(map(lambda x: np.where(x == tf.constant(3))[0], input_ids))\n",
    "        input_segment_array = list(map(lambda x: ( [0] * (x[0] + 1) ) + [1] * ( x[1] - x[0] ), segment_index_lists))\n",
    "        input_segment_array = pad_sequences(input_segment_array, maxlen = self.max_len, padding = 'post')\n",
    "        \n",
    "        input_id_array = pad_sequences(input_ids, maxlen = self.max_len, padding = 'post', dtype = 'int32')\n",
    "        \n",
    "        return [input_id_array, input_segment_array, input_mask_array]\n",
    "    \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return self.get_batch_bert_input_data(sentence_pairs), labels\n",
    "        else:\n",
    "            return self.get_batch_bert_input_data(sentence_pairs)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 24426: expected 3 fields, saw 4\\nSkipping line 156343: expected 3 fields, saw 4\\nSkipping line 218766: expected 3 fields, saw 4\\nSkipping line 232318: expected 3 fields, saw 4\\nSkipping line 253493: expected 3 fields, saw 4\\n'\n",
      "b'Skipping line 265734: expected 3 fields, saw 4\\nSkipping line 282588: expected 3 fields, saw 4\\nSkipping line 350969: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv(r'multinli.train.ko.tsv.txt', sep = '\\t', error_bad_lines = False).dropna().reset_index(drop = True)    \n",
    "train_dataset.gold_label = train_dataset.gold_label.apply(lambda x: categorizer(x))\n",
    "y_train = to_categorical(train_dataset.gold_label, num_classes = 3)\n",
    "train_data = BertSemanticDataGenerator(\n",
    "    train_dataset[['sentence1', 'sentence2']].values.astype('str'), \n",
    "    y_train, \n",
    "    batch_size = 128, \n",
    "    max_len = 128,\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "valid_dataset = pd.read_csv(r'xnli.test.ko.tsv.txt', sep = '\\t', error_bad_lines = False).dropna().reset_index(drop = True)\n",
    "valid_dataset.gold_label = valid_dataset.gold_label.apply(lambda x: categorizer(x))\n",
    "y_valid = to_categorical(valid_dataset.gold_label, num_classes = 3)\n",
    "valid_data = BertSemanticDataGenerator(\n",
    "    valid_dataset[['sentence1', 'sentence2']].values.astype('str'), \n",
    "    y_valid, \n",
    "    batch_size = 128, \n",
    "    max_len = 128,\n",
    "    shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'min',\n",
    "    verbose = 1,\n",
    "    patience = 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4eb270b6c8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f4ec5792a58> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4eb270b6c8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7f4ec5792a58> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f4ec2eaae18> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7f4ec2eaae18> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109693440   input_ids[0][0]                  \n",
      "                                                                 segment_ids[0][0]                \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512, 128)     426496      tf_bert_model[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            771         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 110,120,707\n",
      "Trainable params: 427,267\n",
      "Non-trainable params: 109,693,440\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "3010/3010 [==============================] - ETA: 0s - loss: 0.9743 - accuracy: 0.5214INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "3010/3010 [==============================] - 2925s 972ms/step - loss: 0.9743 - accuracy: 0.5214 - val_loss: 0.8759 - val_accuracy: 0.5931\n",
      "Epoch 2/10\n",
      "3010/3010 [==============================] - 2918s 969ms/step - loss: 0.9286 - accuracy: 0.5601 - val_loss: 0.8547 - val_accuracy: 0.6067\n",
      "Epoch 3/10\n",
      "3010/3010 [==============================] - 2918s 970ms/step - loss: 0.9070 - accuracy: 0.5748 - val_loss: 0.8338 - val_accuracy: 0.6250\n",
      "Epoch 4/10\n",
      "3010/3010 [==============================] - 2918s 969ms/step - loss: 0.8908 - accuracy: 0.5861 - val_loss: 0.8212 - val_accuracy: 0.6369\n",
      "Epoch 5/10\n",
      "3010/3010 [==============================] - 2917s 969ms/step - loss: 0.8788 - accuracy: 0.5937 - val_loss: 0.8146 - val_accuracy: 0.6388\n",
      "Epoch 6/10\n",
      "3010/3010 [==============================] - 2915s 968ms/step - loss: 0.8694 - accuracy: 0.5993 - val_loss: 0.8090 - val_accuracy: 0.6423\n",
      "Epoch 7/10\n",
      "3010/3010 [==============================] - 2909s 966ms/step - loss: 0.8618 - accuracy: 0.6058 - val_loss: 0.7993 - val_accuracy: 0.6480\n",
      "Epoch 8/10\n",
      "3010/3010 [==============================] - 2912s 967ms/step - loss: 0.8548 - accuracy: 0.6096 - val_loss: 0.7946 - val_accuracy: 0.6540\n",
      "Epoch 9/10\n",
      "3010/3010 [==============================] - 2915s 968ms/step - loss: 0.8486 - accuracy: 0.6136 - val_loss: 0.7967 - val_accuracy: 0.6519\n",
      "Epoch 10/10\n",
      "3010/3010 [==============================] - 2916s 969ms/step - loss: 0.8426 - accuracy: 0.6179 - val_loss: 0.7899 - val_accuracy: 0.6521\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "labels = ['contradiction', 'neutral', 'entailment']\n",
    "model = build_model(max_length = 128, gpus = 2)\n",
    "# feature extraction\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data = valid_data,\n",
    "    epochs = EPOCHS,\n",
    "    use_multiprocessing = True,\n",
    "    workers = -1,\n",
    "    callbacks = [early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = BertSemanticDataGenerator(\n",
    "    train_dataset[['sentence1', 'sentence2']].values.astype('str'), \n",
    "    y_train, \n",
    "    batch_size = 24, \n",
    "    max_len = 128,\n",
    "    shuffle = True\n",
    "    )\n",
    "\n",
    "valid_data = BertSemanticDataGenerator(\n",
    "    valid_dataset[['sentence1', 'sentence2']].values.astype('str'), \n",
    "    y_valid, \n",
    "    batch_size = 24, \n",
    "    max_len = 128,\n",
    "    shuffle = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109693440   input_ids[0][0]                  \n",
      "                                                                 segment_ids[0][0]                \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 512, 128)     426496      tf_bert_model[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            771         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 110,120,707\n",
      "Trainable params: 110,120,707\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 202 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "16057/16057 [==============================] - ETA: 0s - loss: 0.8037 - acc: 0.6438WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "16057/16057 [==============================] - 8616s 537ms/step - loss: 0.8037 - acc: 0.6438 - val_loss: 0.7327 - val_acc: 0.6917\n",
      "Epoch 2/50\n",
      "16057/16057 [==============================] - 8606s 536ms/step - loss: 0.7327 - acc: 0.6872 - val_loss: 0.6906 - val_acc: 0.7110\n",
      "Epoch 3/50\n",
      "16057/16057 [==============================] - 8562s 533ms/step - loss: 0.6719 - acc: 0.7185 - val_loss: 0.6754 - val_acc: 0.7160\n",
      "Epoch 4/50\n",
      "16057/16057 [==============================] - 8570s 534ms/step - loss: 0.6163 - acc: 0.7467 - val_loss: 0.6772 - val_acc: 0.7150\n",
      "Epoch 5/50\n",
      "16057/16057 [==============================] - 8578s 534ms/step - loss: 0.5578 - acc: 0.7733 - val_loss: 0.6919 - val_acc: 0.7205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "# fine-tuning\n",
    "model.trainable = True\n",
    "model.compile(\n",
    "    optimizer = Adam(1e-5),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    "    )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(        \n",
    "    train_data,\n",
    "    validation_data = valid_data,\n",
    "    epochs = 50,\n",
    "    use_multiprocessing = True,\n",
    "    workers = -1,\n",
    "    callbacks = [early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000020BA53E7438>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000020BA53E7438>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109693440   input_ids[0][0]                  \n",
      "                                                                 segment_ids[0][0]                \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            771         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 110,120,707\n",
      "Trainable params: 427,267\n",
      "Non-trainable params: 109,693,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(max_length = 128, gpus = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 54.45%')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('델타변이, 마스크도 돌파…대전 태권도장발 185명 집단감염', '27일부터 비수도권 거리두기 3단계로 격상…식당·카페 밤 10시까지(상보)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 48.57%')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('美, 하루 코로나 확진자 10만명 돌파…“6개월만에 최다”', '미, 하루 코로나 확진자 10만명선 넘어…6개월만에 최고치')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 54.95%')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('[올림픽] 김연경, 최초로 올림픽서 4차례 한 경기 30득점 이상', '‘최초’ 김연경, 올림픽서 4차례 한 경기 30득점 이상')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 62.85%')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('원희룡, 지사직 사퇴…\"고뇌했지만 정권교체 위해 던진다\"', '원희룡, 오늘 지사직 사퇴 기자회견…국민의힘 경선 집중')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 54.70%')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('그리고 그가 말했다, \"엄마, 저 왔어요.\"', '그는 한마디도 하지 않았다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neutral', ' 45.63%')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity('그리고 그가 말했다, \"엄마, 저 왔어요.\"', '그는 엄마에게 집에 갔다고 말했다.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
